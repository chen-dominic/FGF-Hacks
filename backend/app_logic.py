# -*- coding: utf-8 -*-
"""FGFHackathon_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fDW-m8s_Gq0O4Qzv_aMbT7lNGqBQFPkQ
"""
# Installed necessary packages using virtual environment
# !pip install langgraph langchain langchain-openai langchain-anthropic langchain-google-genai pandas   
import os
import json
import pandas as pd
from typing import TypedDict, List

import os
import glob
import json
import pandas as pd

from typing import TypedDict, List
from json import JSONDecodeError

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import PromptTemplate
from langgraph.graph import StateGraph, END
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI



import os
import pandas as pd
import glob
import json
from typing import TypedDict, Annotated, List
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, END
import operator

# LLM imports
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# ===================================================================
# SETUP API KEYS
# ===================================================================

# Get API keys
# Read your API keys from environment variables:
ANTHROPIC_API_KEY = ""  # or None if unset
GOOGLE_API_KEY    = ""  #get your own API keys and populate them here!

if not GOOGLE_API_KEY:
    raise RuntimeError("Missing required GOOGLE_API_KEY environment variable")

# Initialize LLMs
if ANTHROPIC_API_KEY:
    claude_llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        anthropic_api_key=ANTHROPIC_API_KEY,
        temperature=0.1
    )
    print("âœ… Claude initialized")
else:
    # Fallback: Use Gemini for strategic agent too
    claude_llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.3
    )
    print("âš ï¸ Using Gemini for strategic agent (Claude key not provided)")

gemini_llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",
    google_api_key=GOOGLE_API_KEY,
    temperature=0.1
)
print("âœ… Gemini initialized")

def load_real_fgf_data():
    """
    Load all CSVs in the project root (parent of this backend folder)
    into categorized DataFrames, based on your file_mappings.
    """

    # where your project root lives (one level up from this file)
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))

    # find every .csv in that folder
    csv_paths = glob.glob(os.path.join(base_dir, "*.csv"))
    if not csv_paths:
        raise FileNotFoundError(f"No CSV files found in {base_dir}")

    # mapping of category â†’ possible filename fragments
    file_mappings = {
        'sales':       ['fgf_sales_data', 'sales_data', 'fgf_sales'],
        'reviews':     ['customer_reviews', 'reviews', 'customer_review_data'],
        'trends':      ['market_trends', 'trends', 'trend_data'],
        'competitors': ['competitor_analysis', 'competitors', 'competitor_data'],
        'suppliers':   ['supplier_costs', 'suppliers', 'supplier_data']
    }

    datasets = {}

    for path in csv_paths:
        fname = os.path.basename(path).lower()
        # pick a category whose mapping matches this filename
        category = None
        for cat, patterns in file_mappings.items():
            if any(pat in fname for pat in patterns):
                category = cat
                break
        # if no mapping hit, you can skip or assign to 'unknown'
        if category is None:
            continue

        # load it
        df = pd.read_csv(path)
        datasets[category] = df
        print(f"âœ… Loaded {category}: {fname} â†’ {df.shape}")

    # check essential ones
    for essential in ('sales','trends'):
        if essential not in datasets:
            print(f"âš ï¸ Missing essential dataset: {essential}")

    return datasets
    

def get_data_insights(datasets):
    """Show insights about the loaded data"""

    print(f"\nğŸ“Š DATASET OVERVIEW:")
    print("=" * 30)

    for name, df in datasets.items():
        print(f"\nğŸ“ˆ {name.upper()} DATA:")
        print(f"   Rows: {len(df):,}")
        print(f"   Columns: {list(df.columns)}")

        # Show sample data
        if len(df) > 0:
            print(f"   Sample: {df.iloc[0].to_dict()}")

        # Data-specific insights
        if name == 'sales' and 'item_name' in df.columns:
            top_items = df['item_name'].value_counts().head(3)
            print(f"   Top items: {list(top_items.index)}")

        elif name == 'trends' and 'trend_keyword' in df.columns:
            keywords = df['trend_keyword'].unique()
            print(f"   Keywords tracked: {list(keywords)[:5]}")

        elif name == 'reviews' and 'sentiment' in df.columns:
            sentiment_dist = df['sentiment'].value_counts()
            print(f"   Sentiment: {dict(sentiment_dist)}")

# Load your actual FGF data
print("ğŸ“Š Loading your real FGF datasets...")
fgf_datasets = load_real_fgf_data()

# Show data insights
if fgf_datasets:
    get_data_insights(fgf_datasets)

    # Extract main datasets for easy access
    sales_df = fgf_datasets.get('sales', pd.DataFrame())
    trends_df = fgf_datasets.get('trends', pd.DataFrame())
    reviews_df = fgf_datasets.get('reviews', pd.DataFrame())
    competitors_df = fgf_datasets.get('competitors', pd.DataFrame())
    suppliers_df = fgf_datasets.get('suppliers', pd.DataFrame())

    print(f"\nğŸ¯ Ready for analysis with {len(fgf_datasets)} datasets!")
else:
    print("âŒ No datasets loaded. Please upload your CSV files.")



def initialize_llms(google_key, anthropic_key=None):
    """Initialize all LLM instances for our agents"""

    print("ğŸ¤– Initializing LLM instances...")

    # Supervisor Gemini (for coordination and final synthesis)
    supervisor_llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",
        google_api_key=google_key,
        temperature=0.1  # Low temperature for logical decisions
    )
    print("âœ… Supervisor LLM (Gemini) initialized")

    # Strategic Agent - Claude if available, otherwise Gemini
    if anthropic_key:
        strategic_llm = ChatAnthropic(
            model="claude-3-5-sonnet-20241022",
            anthropic_api_key=anthropic_key,
            temperature=0.2  # Slightly higher for creativity
        )
        print("âœ… Strategic LLM (Claude) initialized")
    else:
        strategic_llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-pro",
            google_api_key=google_key,
            temperature=0.3  # Higher temperature for creative thinking
        )
        print("âœ… Strategic LLM (Gemini - Creative Mode) initialized")

    # Validation Agent (always Gemini)
    validation_llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",  # Faster model for validation tasks
        google_api_key=google_key,
        temperature=0.1  # Low temperature for analytical precision
    )
    print("âœ… Validation LLM (Gemini Flash) initialized")

    return supervisor_llm, strategic_llm, validation_llm

# Initialize all LLMs
supervisor_llm, strategic_llm, validation_llm = initialize_llms(GOOGLE_API_KEY, ANTHROPIC_API_KEY)

# ===================================================================
# TEST THE SETUP
# ===================================================================

import json
from typing import TypedDict, List
from json import JSONDecodeError
from langchain import PromptTemplate

# Assume supervisor_llm, strategic_llm, validation_llm are already initialized via your initialize_llms

# 1. Define the BakeryState
class BakeryState(TypedDict, total=False):
    history: List[dict]               # conversation history
    strategic_result: dict           # output of the strategic agent
    validation_result: dict          # output of the validation agent
    final_recommendation: str        # output of the synthesis agent
    raw_response: str                # capture if JSON parsing fails
    next_agent: str                  # which agent to run next

# 2. Supervisor Orchestrator
def supervisor_step(state: BakeryState) -> BakeryState:
    if "strategic_result" not in state:
        state["next_agent"] = "strategic"
    elif "validation_result" not in state:
        state["next_agent"] = "validation"
    elif "final_recommendation" not in state:
        state["next_agent"] = "synthesis"
    else:
        state["next_agent"] = "done"
    return state

# 3. Create PromptTemplates and Chains
strategic_prompt = PromptTemplate(
    input_variables=["sales_df", "reviews_df", "trends_df", "user_query"],
    template="""
You are the Strategic Bakery Consultant creating a comprehensive product analysis.

Dataframes provided:
- Sales: columns date, item_name, units_sold, price, food_cost, etc.
- Reviews: ratings & review text
- Trends: keywords, search volumes, growth rates

User query: "{user_query}"

Create a COMPREHENSIVE analysis with rich detail for frontend display.

Return JSON with this EXACT structure:
{{
    "product_concept": {{
        "name": "Creative Product Name",
        "tagline": "Catchy one-liner for marketing",
        "description": "2-3 sentence detailed description",
        "category": "bread/pastry/dessert/seasonal",
        "price": 8.99,
        "target_audience": "Primary customer segment",
        "key_ingredients": ["ingredient1", "ingredient2", "ingredient3"],
        "unique_selling_points": ["USP1", "USP2", "USP3"],
        "flavor_profile": "Taste description",
        "visual_appeal": "How it looks/presentation"
    }},
    "market_analysis": {{
        "opportunity_score": 85,
        "market_size": "Large/Medium/Small",
        "growth_trend": "Rising/Stable/Declining",
        "seasonality": "Year-round/Spring/Summer/Fall/Winter/Holiday",
        "competition_level": "Low/Medium/High",
        "target_demographics": ["demo1", "demo2"],
        "market_insights": [
            "Key insight 1",
            "Key insight 2",
            "Key insight 3"
        ],
        "trend_data": {{
            "search_volume": 1250,
            "growth_rate": "15%",
            "peak_months": ["October", "November"]
        }}
    }},
    "positioning_strategy": {{
        "price_tier": "Premium/Mid-tier/Value",
        "positioning_statement": "How we position vs competitors",
        "competitive_advantage": "What makes us different",
        "marketing_channels": ["channel1", "channel2"],
        "launch_strategy": "Recommended approach"
    }},
    "success_metrics": {{
        "target_daily_sales": 45,
        "break_even_units": 25,
        "projected_monthly_revenue": 5400,
        "customer_acquisition_target": 150
    }},
    "risks_opportunities": {{
        "opportunities": ["opp1", "opp2"],
        "risks": ["risk1", "risk2"],
        "mitigation_strategies": ["strategy1", "strategy2"]
    }}
}}
"""
)
strategic_chain = strategic_prompt | strategic_llm

validation_prompt = PromptTemplate(
    input_variables=["strategic", "suppliers_df", "competitors_df"],
    template="""
You are the Bakery Operations & Financial Expert creating detailed feasibility analysis.

Strategic Concept: {strategic}

Dataframes:
- Suppliers: ingredient costs, lead times, quality scores
- Competitors: pricing, market share, ratings

Provide COMPREHENSIVE validation data for frontend display.

Return JSON with this EXACT structure:
{{
    "financial_analysis": {{
        "cost_breakdown": {{
            "ingredients": 2.45,
            "labor": 1.20,
            "overhead": 0.80,
            "packaging": 0.35,
            "total_cogs": 4.80
        }},
        "pricing_analysis": {{
            "suggested_price": 8.99,
            "gross_margin": 4.19,
            "margin_percentage": 46.6,
            "competitor_avg_price": 7.85,
            "price_positioning": "Premium"
        }},
        "profitability": {{
            "daily_break_even": 25,
            "projected_daily_sales": 45,
            "daily_profit": 188.55,
            "monthly_profit": 5656.50,
            "roi_months": 3.2
        }}
    }},
    "operational_feasibility": {{
        "production_complexity": "Simple/Moderate/Complex",
        "skill_level_required": "Basic/Intermediate/Advanced",
        "equipment_needed": ["mixer", "oven", "proofing area"],
        "production_time": {{
            "prep_time": "45 minutes",
            "bake_time": "25 minutes",
            "cooling_time": "30 minutes",
            "total_time": "100 minutes"
        }},
        "daily_capacity": 120,
        "shelf_life": "3 days",
        "storage_requirements": "Room temperature display case"
    }},
    "supply_chain": {{
        "ingredient_availability": "High/Medium/Low",
        "supplier_reliability": 4.2,
        "lead_times": {{
            "flour": "2 days",
            "specialty_items": "5-7 days"
        }},
        "cost_stability": "Stable/Volatile",
        "alternative_suppliers": 3
    }},
    "competitive_analysis": {{
        "direct_competitors": 4,
        "price_advantage": "+$1.14",
        "quality_differentiation": "Higher",
        "market_gap": "Premium artisan segment underserved",
        "competitive_threats": ["threat1", "threat2"]
    }},
    "risk_assessment": {{
        "financial_risks": [
            {{"risk": "Ingredient cost inflation", "probability": "Medium", "impact": "Medium"}},
            {{"risk": "Lower than expected demand", "probability": "Low", "impact": "High"}}
        ],
        "operational_risks": [
            {{"risk": "Production complexity", "probability": "Low", "impact": "Medium"}},
            {{"risk": "Quality consistency", "probability": "Medium", "impact": "High"}}
        ],
        "overall_risk_score": 3.2
    }},
    "validation_summary": {{
        "feasible": true,
        "confidence_score": 87,
        "recommendation": "APPROVE/CONDITIONAL/REJECT",
        "key_conditions": ["condition1", "condition2"],
        "timeline_to_launch": "4-6 weeks"
    }}
}}
"""
)
validation_chain = validation_prompt | validation_llm


synthesis_prompt = PromptTemplate(
    input_variables=["strategic", "validation"],
    template="""
You are the Executive Dashboard Generator for FGF Bakery.

Strategic Analysis: {strategic}
Validation Analysis: {validation}

Create a COMPREHENSIVE executive summary with rich data for dashboard display.

Return JSON with this EXACT structure:
{{
    "executive_decision": {{
        "recommendation": "APPROVE/CONDITIONAL/REJECT",
        "confidence_level": 87,
        "decision_rationale": "2-3 sentence explanation",
        "go_to_market_timeline": "6-8 weeks",
        "investment_required": 2500
    }},
    "key_metrics_dashboard": {{
        "revenue_projection": {{
            "monthly": 5656,
            "quarterly": 16968,
            "annual": 67872
        }},
        "profitability": {{
            "gross_margin": "46.6%",
            "daily_profit": 188.55,
            "break_even_days": 13
        }},
        "market_potential": {{
            "opportunity_score": 87,
            "market_size": "Medium",
            "growth_potential": "High"
        }},
        "operational_readiness": {{
            "complexity_score": 6,
            "resource_requirements": "Moderate",
            "time_to_launch": "6 weeks"
        }}
    }},
    "comparison_to_portfolio": {{
        "vs_bestseller": {{
            "margin_difference": "+12%",
            "complexity_vs_bestseller": "Similar",
            "revenue_potential": "125% of average"
        }},
        "portfolio_fit": "Excellent addition to premium line",
        "cannibalization_risk": "Low"
    }},
    "implementation_roadmap": {{
        "phase_1": {{
            "name": "Recipe Development",
            "duration": "2 weeks",
            "key_activities": ["Recipe testing", "Cost optimization", "Supplier negotiations"]
        }},
        "phase_2": {{
            "name": "Production Setup",
            "duration": "2 weeks",
            "key_activities": ["Staff training", "Equipment setup", "Quality standards"]
        }},
        "phase_3": {{
            "name": "Market Launch",
            "duration": "2 weeks",
            "key_activities": ["Soft launch", "Customer feedback", "Marketing campaign"]
        }}
    }},
    "success_indicators": {{
        "week_1_targets": {{
            "units_sold": 150,
            "customer_feedback": "4.0+",
            "production_efficiency": "80%"
        }},
        "month_1_targets": {{
            "monthly_revenue": 4500,
            "repeat_customers": 40,
            "margin_achievement": "45%+"
        }}
    }},
    "stakeholder_summary": {{
        "for_ceo": "One-liner bottom line impact",
        "for_operations": "Key operational implications",
        "for_marketing": "Marketing positioning summary",
        "for_finance": "Financial impact summary"
    }}
}}
"""
)
synthesis_chain = synthesis_prompt | supervisor_llm

# 4. Agent Runners with JSON error handling

def run_strategic(state: BakeryState, datasets: dict) -> BakeryState:
    user_query = state['history'][-1]['content']
    response = strategic_chain.invoke({
        'sales_df': datasets['sales'],
        'reviews_df': datasets['reviews'],
        'trends_df': datasets['trends'],
        'user_query': user_query
    })
    text = getattr(response, 'content', response)
    try:
        parsed = json.loads(text)
        state['strategic_result'] = parsed
    except JSONDecodeError:
        state['raw_response'] = text
        parsed = {}
    state['history'].append({'role': 'assistant', 'content': text})
    return state


def run_validation(state: BakeryState, datasets: dict) -> BakeryState:
    strat_json = json.dumps(state.get('strategic_result', {}))
    response = validation_chain.invoke({
        'strategic': strat_json,
        'suppliers_df': datasets['suppliers'],
        'competitors_df': datasets['competitors']
    })
    text = getattr(response, 'content', response)
    try:
        parsed = json.loads(text)
        state['validation_result'] = parsed
    except JSONDecodeError:
        state['raw_response'] = text
        parsed = {}
    state['history'].append({'role': 'assistant', 'content': text})
    return state


def run_synthesis(state: BakeryState) -> BakeryState:
    strat_json = json.dumps(state.get('strategic_result', {}))
    val_json = json.dumps(state.get('validation_result', {}))
    response = synthesis_chain.invoke({
        'strategic': strat_json,
        'validation': val_json
    })
    text = getattr(response, 'content', response)
    try:
        # Synthesis is plain text, so just store
        state['final_recommendation'] = text
    except Exception:
        state['raw_response'] = text
    state['history'].append({'role': 'assistant', 'content': text})
    return state

# 5. Conversation Loop

def chat_with_bakery(state: BakeryState, datasets: dict, user_msg: str) -> str:
    state.setdefault('history', []).append({'role': 'user', 'content': user_msg})
    state = supervisor_step(state)

    if state['next_agent'] == 'strategic':
        state = run_strategic(state, datasets)
    elif state['next_agent'] == 'validation':
        state = run_validation(state, datasets)
    elif state['next_agent'] == 'synthesis':
        state = run_synthesis(state)
    else:
        state['history'].append({'role': 'assistant', 'content': 'Analysis complete!'})

    return state['history'][-1]['content']

